{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ez3RMYF65e3f",
        "QDl3UOg3emWG",
        "EsTh0AyGMSz9",
        "zjxriPTB5l1y",
        "AwAnUmpJjRkC",
        "IM8gDdgf6CK4",
        "nnsbop-mfO-F",
        "IMep8Y5GfkuG",
        "MhhyLs9O6NC4",
        "xktF71gasRKA",
        "0dRRou_y60M5",
        "8AM3S94Lr3sU",
        "5ogMHGH4642r",
        "KIwF6z957Bor"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6cb9e3821cbc42db91baf6d2a6fe27b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_803462958a1e4d1a8739817f7e5251a7",
              "IPY_MODEL_6479fba1e59a4750a38495a9f5499fb8",
              "IPY_MODEL_755179e878b746d7a8c789b82e446b5e"
            ],
            "layout": "IPY_MODEL_7fecbed826a54daaa3a57c241bcfe363"
          }
        },
        "803462958a1e4d1a8739817f7e5251a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac8b79571de14930baa1f3e88620c04c",
            "placeholder": "​",
            "style": "IPY_MODEL_796f50179c574fe9aeeb6ad6b8ce5acf",
            "value": ""
          }
        },
        "6479fba1e59a4750a38495a9f5499fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18a99972301b412989e4432b1fe44170",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99e3014646584580b6c02a40bc8025c5",
            "value": 0
          }
        },
        "755179e878b746d7a8c789b82e446b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1720e7b494b24056b8f9eed47a5b8239",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5579c4f2d54b3cb9462fae9015cfb3",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "7fecbed826a54daaa3a57c241bcfe363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8b79571de14930baa1f3e88620c04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796f50179c574fe9aeeb6ad6b8ce5acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18a99972301b412989e4432b1fe44170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "99e3014646584580b6c02a40bc8025c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1720e7b494b24056b8f9eed47a5b8239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5579c4f2d54b3cb9462fae9015cfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06f7bf0b1f942f5980d91e9282b9da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d30bdb214674bc1813b26f25484e644",
              "IPY_MODEL_416808966ee849a3b502b9e3248791d7",
              "IPY_MODEL_c5962caab56c47c89612eedf513f2865"
            ],
            "layout": "IPY_MODEL_8702e0c7ba354cf08c4d1c62c27562db"
          }
        },
        "7d30bdb214674bc1813b26f25484e644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdcd2a9ed299409384d6164831431f09",
            "placeholder": "​",
            "style": "IPY_MODEL_c5992d3baf0840ecb8e7c2c8eacf1d8c",
            "value": "Downloading: 100%"
          }
        },
        "416808966ee849a3b502b9e3248791d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c2f2dc83944ac8816550fbc9391651",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_829584b8b1f74597bc5f9d6c07516fdb",
            "value": 791656
          }
        },
        "c5962caab56c47c89612eedf513f2865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7843009a8162484791e86aeaf7f5e4f5",
            "placeholder": "​",
            "style": "IPY_MODEL_7319735e8a714ce2a90cc6e37595fcc9",
            "value": " 792k/792k [00:00&lt;00:00, 2.59MB/s]"
          }
        },
        "8702e0c7ba354cf08c4d1c62c27562db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcd2a9ed299409384d6164831431f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5992d3baf0840ecb8e7c2c8eacf1d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89c2f2dc83944ac8816550fbc9391651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829584b8b1f74597bc5f9d6c07516fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7843009a8162484791e86aeaf7f5e4f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7319735e8a714ce2a90cc6e37595fcc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58d8f6612e7543fc85116c22213f0833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf0139190ab14b43a11daa12f454d913",
              "IPY_MODEL_80ca538aacc745f2b882fe16f985704d",
              "IPY_MODEL_4fa23c15742749eb978a7e526a74de31"
            ],
            "layout": "IPY_MODEL_7a6aa86b25ea4947971bba343daf4318"
          }
        },
        "cf0139190ab14b43a11daa12f454d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b70346c488433692199e604e8fbc67",
            "placeholder": "​",
            "style": "IPY_MODEL_79fb1d6939d2469a9cb2ecbef0214e20",
            "value": "Downloading: 100%"
          }
        },
        "80ca538aacc745f2b882fe16f985704d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3875599e13a345a7a12f0ceadcb124e4",
            "max": 1199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9d9fe92e4854c6eba273cccfbe85dc1",
            "value": 1199
          }
        },
        "4fa23c15742749eb978a7e526a74de31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb72d7f0422347cdb3852c2953dc6ded",
            "placeholder": "​",
            "style": "IPY_MODEL_3934819ede134c579121e8123c404ed7",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 22.9kB/s]"
          }
        },
        "7a6aa86b25ea4947971bba343daf4318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b70346c488433692199e604e8fbc67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fb1d6939d2469a9cb2ecbef0214e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3875599e13a345a7a12f0ceadcb124e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d9fe92e4854c6eba273cccfbe85dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb72d7f0422347cdb3852c2953dc6ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3934819ede134c579121e8123c404ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/disi-unibo-nlp/bio-ee-egv/blob/main/notebooks/create_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez3RMYF65e3f"
      },
      "source": [
        "# Setup"
      ],
      "id": "Ez3RMYF65e3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDl3UOg3emWG"
      },
      "source": [
        "## Constants"
      ],
      "id": "QDl3UOg3emWG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOjw6EBocj5O"
      },
      "source": [
        "random_seed = 42\n",
        "test_size_ratio = 0.1\n",
        "min_class_occurance = 1\n",
        "train_set_name = 'train'\n",
        "validation_set_name = 'validation'\n",
        "test_set_name = 'test'\n",
        "datasets_type = '.tsv'\n",
        "datasets_separator = '\\t'\n",
        "dataset_file_name = 'dataset.zip'\n",
        "ann_datasets = ['genia-mk']\n",
        "t5_version = \"base\"\n",
        "dataset_url = 'https://raw.githubusercontent.com/disi-unibo-nlp/bio-ee-egv/main/data/datasets/original_datasets.tar.gz'"
      ],
      "id": "EOjw6EBocj5O",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsTh0AyGMSz9"
      },
      "source": [
        "## Imports"
      ],
      "id": "EsTh0AyGMSz9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "6cb9e3821cbc42db91baf6d2a6fe27b8",
            "803462958a1e4d1a8739817f7e5251a7",
            "6479fba1e59a4750a38495a9f5499fb8",
            "755179e878b746d7a8c789b82e446b5e",
            "7fecbed826a54daaa3a57c241bcfe363",
            "ac8b79571de14930baa1f3e88620c04c",
            "796f50179c574fe9aeeb6ad6b8ce5acf",
            "18a99972301b412989e4432b1fe44170",
            "99e3014646584580b6c02a40bc8025c5",
            "1720e7b494b24056b8f9eed47a5b8239",
            "7f5579c4f2d54b3cb9462fae9015cfb3",
            "d06f7bf0b1f942f5980d91e9282b9da5",
            "7d30bdb214674bc1813b26f25484e644",
            "416808966ee849a3b502b9e3248791d7",
            "c5962caab56c47c89612eedf513f2865",
            "8702e0c7ba354cf08c4d1c62c27562db",
            "bdcd2a9ed299409384d6164831431f09",
            "c5992d3baf0840ecb8e7c2c8eacf1d8c",
            "89c2f2dc83944ac8816550fbc9391651",
            "829584b8b1f74597bc5f9d6c07516fdb",
            "7843009a8162484791e86aeaf7f5e4f5",
            "7319735e8a714ce2a90cc6e37595fcc9",
            "58d8f6612e7543fc85116c22213f0833",
            "cf0139190ab14b43a11daa12f454d913",
            "80ca538aacc745f2b882fe16f985704d",
            "4fa23c15742749eb978a7e526a74de31",
            "7a6aa86b25ea4947971bba343daf4318",
            "e2b70346c488433692199e604e8fbc67",
            "79fb1d6939d2469a9cb2ecbef0214e20",
            "3875599e13a345a7a12f0ceadcb124e4",
            "a9d9fe92e4854c6eba273cccfbe85dc1",
            "eb72d7f0422347cdb3852c2953dc6ded",
            "3934819ede134c579121e8123c404ed7"
          ]
        },
        "id": "77d3785d",
        "outputId": "161caea3-3f59-44fa-ee8c-3d0794d6d709"
      },
      "source": [
        "!pip install tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "\n",
        "import os, glob, re, spacy, tarfile, torch, itertools, csv, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import T5Tokenizer, BartTokenizer\n",
        "from google.colab import files\n",
        "\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "tokenizerT5 = T5Tokenizer.from_pretrained(\"t5-\" + t5_version)"
      ],
      "id": "77d3785d",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 6.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb9e3821cbc42db91baf6d2a6fe27b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d06f7bf0b1f942f5980d91e9282b9da5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58d8f6612e7543fc85116c22213f0833"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjxriPTB5l1y"
      },
      "source": [
        "## Downloads"
      ],
      "id": "zjxriPTB5l1y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08e67325",
        "outputId": "282d3135-cbec-40e3-d98a-9b2f56a05ab4"
      },
      "source": [
        "!rm -R /content/dataset\n",
        "os.chdir(\"/content\")\n",
        "!wget {dataset_url}\n",
        "tar = tarfile.open(dataset_url.split(\"/\")[-1])\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "!rm original_datasets.tar.gz\n",
        "os.chdir(\"./dataset\")\n",
        "!python3 -m spacy download en_core_web_sm"
      ],
      "id": "08e67325",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset': No such file or directory\n",
            "--2022-09-15 12:43:32--  https://raw.githubusercontent.com/disi-unibo-nlp/bio-ee-egv/main/data/datasets/original_datasets.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9032157 (8.6M) [application/octet-stream]\n",
            "Saving to: ‘original_datasets.tar.gz’\n",
            "\n",
            "original_datasets.t 100%[===================>]   8.61M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-09-15 12:43:32 (158 MB/s) - ‘original_datasets.tar.gz’ saved [9032157/9032157]\n",
            "\n",
            "2022-09-15 12:43:53.702501: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwAnUmpJjRkC"
      },
      "source": [
        "# Functions"
      ],
      "id": "AwAnUmpJjRkC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM8gDdgf6CK4"
      },
      "source": [
        "## Read files"
      ],
      "id": "IM8gDdgf6CK4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwj1iBGBjYg7"
      },
      "source": [
        "datasetsNames = [datasetName[:-1] for datasetName in glob.glob(\"*/\")]"
      ],
      "id": "Jwj1iBGBjYg7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "959bc9a5"
      },
      "source": [
        "datasets = {}\n",
        "for datasetName in datasetsNames:\n",
        "  filelist = [filename for filename in glob.glob(\"./\" + datasetName + \"/*.*\")] # exclude README and LICENSE\n",
        "  articleIDs = {}  \n",
        "  for i, x in enumerate(filelist):  \n",
        "      key = os.path.basename(x).split('.')[0]\n",
        "      group = articleIDs.get(key,[])\n",
        "      group.append(x)  \n",
        "      articleIDs[key] = group\n",
        "  datasets[datasetName] = articleIDs\n",
        "#print(datasets)  # datasetName -> list of triples (abstract, extracted entities, extracted events)"
      ],
      "id": "959bc9a5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnsbop-mfO-F"
      },
      "source": [
        "### Read .a1/.a2"
      ],
      "id": "nnsbop-mfO-F"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdbaadfb"
      },
      "source": [
        "predictions = {}\n",
        "goldEntities = {}\n",
        "abstracts = {}\n",
        "debugStructure = {}\n",
        "\n",
        "for dataset in datasets.keys():\n",
        "  if not dataset in ann_datasets:\n",
        "    debugStructure[dataset] = {}\n",
        "    predictions[dataset] = []\n",
        "    goldEntities[dataset] = []\n",
        "    abstracts[dataset] = []\n",
        "    for article in datasets[dataset]:\n",
        "      predictionFile = [x for x in datasets[dataset][article] if \"a2\" in x][0]\n",
        "      entityFile = [x for x in datasets[dataset][article] if \"a1\" in x][0]\n",
        "      abstractFile = [x for x in datasets[dataset][article] if \"txt\" in x][0]\n",
        "      with open(predictionFile) as f:\n",
        "          predictionList = {}\n",
        "          for row in f.readlines():\n",
        "              # Clean up\n",
        "              temp = row.replace(\"\\t\", \"%%&%%\").replace(\"\\n\", \"\").split(\"%%&%%\")\n",
        "              temp[1] = re.split('\\s|;', temp[1])\n",
        "              dictId = temp[0] \n",
        "              temp.pop(0)\n",
        "              predictionList[dictId] = temp\n",
        "          predictions[dataset].append(predictionList)\n",
        "          \n",
        "      with open(entityFile) as f:\n",
        "          entityList = {}\n",
        "          for row in f.readlines():\n",
        "              # Clean up\n",
        "              temp = row.replace(\"\\t\", \"%%&%%\").replace(\"\\n\", \"\").split(\"%%&%%\") ; \n",
        "              temp[1] = re.split('\\s|;', temp[1])\n",
        "              dictId = temp[0] \n",
        "              temp.pop(0)\n",
        "              entityList[dictId] = temp\n",
        "          goldEntities[dataset].append(entityList)\n",
        "\n",
        "      abstract = \"\"\n",
        "          \n",
        "      with open(abstractFile) as f:\n",
        "          abstract = f.read()\n",
        "          abstracts[dataset].append(abstract)\n",
        "\n",
        "      debugStructure[dataset][article] = {}\n",
        "      debugStructure[dataset][article]['predictions'] = predictionList\n",
        "      debugStructure[dataset][article]['entitities'] = entityList\n",
        "      debugStructure[dataset][article]['abstract'] = abstract"
      ],
      "id": "bdbaadfb",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMep8Y5GfkuG"
      },
      "source": [
        "### Read .ann"
      ],
      "id": "IMep8Y5GfkuG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjtH-rOnhDNd"
      },
      "source": [
        "articles = {}\n",
        "\n",
        "for dataset in datasets.keys():\n",
        "  if dataset in ann_datasets:\n",
        "    predictions[dataset] = []\n",
        "    abstracts[dataset] = []\n",
        "    for i, article in enumerate(datasets[dataset]):\n",
        "      articles[i] = article\n",
        "      predictionFile = [x for x in datasets[dataset][article] if \"ann\" in x][0]\n",
        "      abstractFile = [x for x in datasets[dataset][article] if \"txt\" in x][0]\n",
        "      with open(predictionFile) as f:\n",
        "          predictionList = {}\n",
        "          for row in f.readlines():\n",
        "              # Clean up\n",
        "              temp = row.replace(\"\\t\", \"%%&%%\").replace(\"\\n\", \"\").split(\"%%&%%\") ; \n",
        "              temp[1] = re.split('\\s|;', temp[1])\n",
        "              dictId = temp[0] \n",
        "              temp.pop(0)\n",
        "              predictionList[dictId] = temp\n",
        "          predictions[dataset].append(predictionList)\n",
        "          \n",
        "      with open(abstractFile) as f:\n",
        "          abstracts[dataset].append(f.read())"
      ],
      "id": "ZjtH-rOnhDNd",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhhyLs9O6NC4"
      },
      "source": [
        "## Utility functions"
      ],
      "id": "MhhyLs9O6NC4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ucgNjci6Pps"
      },
      "source": [
        "# Load the Spacy model to use for tokenization\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def sentence_tokenization(text, spacy_model=nlp):\n",
        "    if (spacy_model is None):\n",
        "        # Match punctuation characters and add spaces after them\n",
        "        sentences = re.sub(r'([.,!?()]+)([a-zA-Z0-9_])', r'\\1 \\2', text)\n",
        "        # Collapse multiple spaces\n",
        "        sentences = re.sub('\\s{2,}', ' ', text)\n",
        "    else:\n",
        "        doc = spacy_model(text)\n",
        "        #print([sent for sent in doc.sents])\n",
        "        sentences = [{'sentence': str(sent).strip(), 'start_index': sent.start_char, 'end_index': sent.end_char} \n",
        "          for sent in doc.sents]\n",
        "    return sentences"
      ],
      "id": "-ucgNjci6Pps",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View [Manipulate datasets section](#datasets-maniuplation) to interpret these magic numbers ;)"
      ],
      "metadata": {
        "id": "jx8XQdgFjmN_"
      },
      "id": "jx8XQdgFjmN_"
    },
    {
      "cell_type": "code",
      "source": [
        "def select_sentence_class(sentence):\n",
        "  length = len(sentence)\n",
        "  if length <= 123:\n",
        "    return 'S'\n",
        "  if length <= 182:\n",
        "    return 'M'\n",
        "  return 'L'"
      ],
      "metadata": {
        "id": "i7MwhPz-K1jn"
      },
      "id": "i7MwhPz-K1jn",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean sets that contain elements that are sub-elements of others."
      ],
      "metadata": {
        "id": "kNKleSJdx22b"
      },
      "id": "kNKleSJdx22b"
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_set(my_set):\n",
        "    my_list = list(my_set)\n",
        "    my_list.sort(key=lambda s: len(s), reverse=True)\n",
        "    out = []\n",
        "    for s in my_list:\n",
        "        if not any([s in o for o in out]) and not s == \"\":\n",
        "             out.append(s)\n",
        "    return out"
      ],
      "metadata": {
        "id": "Tvowf33qXa0i"
      },
      "id": "Tvowf33qXa0i",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python Dict object into a `.csv` file."
      ],
      "metadata": {
        "id": "NFpxj7eIxPVE"
      },
      "id": "NFpxj7eIxPVE"
    },
    {
      "cell_type": "code",
      "source": [
        "def write_dict_to_csv(filename, myDict):\n",
        "  with open(filename, 'w') as csv_file:  \n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in sorted(myDict.items()):\n",
        "       writer.writerow([key, value])"
      ],
      "metadata": {
        "id": "ljQn7RGREzbc"
      },
      "id": "ljQn7RGREzbc",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debug function. It retrives (the first occurrence of) `articleID` given a sentence as input."
      ],
      "metadata": {
        "id": "PKnFndUaxdaI"
      },
      "id": "PKnFndUaxdaI"
    },
    {
      "cell_type": "code",
      "source": [
        "def retrive_article_ID_by_sentence(sentence, dataset_name):\n",
        "  for article in datasets[dataset_name]:\n",
        "    abstractFile = [x for x in datasets[dataset_name][article] if \"txt\" in x][0]\n",
        "    with open(abstractFile) as f:\n",
        "        if sentence in f.read():\n",
        "          return abstractFile.split(\"/\")[-1].split(\".\")[0]\n",
        "  return False"
      ],
      "metadata": {
        "id": "vy1BIeHoT86C"
      },
      "id": "vy1BIeHoT86C",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9EPQsOLsn5w"
      },
      "source": [
        "## Event creation"
      ],
      "id": "L9EPQsOLsn5w"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6c833377"
      },
      "source": [
        "def subsitute_object_with_content(datasetName, file_number, relationObject):\n",
        "    objectContent = object\n",
        "    try:\n",
        "        objectContent = prediction[relationObject]\n",
        "    except: # if not found search in goldEntities\n",
        "        objectContent = goldEntities[datasetName][file_number][relationObject]\n",
        "    return objectContent\n",
        "\n",
        "def process_arguments(arguments, datasetName, file_number, event):\n",
        "  relations = []\n",
        "  for argument in arguments:  # exclude the trigger\n",
        "    if argument:\n",
        "      inner = {}\n",
        "      inner['predicate'] = argument.rsplit(':')[0]\n",
        "      relationObject = argument.rsplit(':')[1]\n",
        "      if \"E\" in relationObject:\n",
        "        #eventsMentioned.append(relationObject)\n",
        "        nestedEvent = events[relationObject]\n",
        "        #print(os.linesep + \"\\tNested event found: \" + relationObject + \" \" + str(nestedEvent) + os.linesep)\n",
        "        relationObject = create_event(datasetName, file_number, \\\n",
        "                                      (relationObject, events[relationObject]))\n",
        "        inner['object'] = relationObject\n",
        "      else:\n",
        "        inner['object'] = subsitute_object_with_content(datasetName, file_number, relationObject)\n",
        "      relations.append(inner)\n",
        "  return relations\n",
        "\n",
        "def create_event(datasetName, file_number, event):\n",
        "    eventID = event[0]\n",
        "    myEvent = {}\n",
        "    myEvent['eventID'] = event[0]\n",
        "    myEvent['subject'] = prediction[event[1][0][0].rsplit(':')[1]] # subject = trigger ID\n",
        "    myEvent['relations'] = process_arguments(event[1][0][1:], datasetName, file_number, event)\n",
        "    return myEvent\n",
        "\n",
        "def create_serialized_event(triple, modifiers, eventID, nested = False, roleEvent = None, parentEvent = None, nodeNumber = 0):\n",
        "  serializedEvent = []\n",
        "  serializedEvent.append(\"[\")\n",
        "  serializedEvent.append(triple['subject'][1] + \" | \" + triple['subject'][0][0])\n",
        "  eventModifier = []\n",
        "  nodeNumber += 1\n",
        "  # If exist modifiers for this event\n",
        "  if eventID in modifiers.keys():\n",
        "    eventModifier = modifiers[eventID]\n",
        "  for modifier in eventModifier:\n",
        "    serializedEvent.append(\"|\")\n",
        "    serializedEvent.append(modifier[0] + \" = \" + modifier[1])\n",
        "  if nested:\n",
        "    serializedEvent.append(\" | \" + roleEvent + \" = \" + parentEvent)\n",
        "  serializedEvent.append(\"]\")\n",
        "  for relation in triple['relations']:\n",
        "      predicate = relation['predicate']\n",
        "      trigger = triple['subject'][1]\n",
        "      relationObject = \"[\"\n",
        "      try:\n",
        "        nodeNumber += 1\n",
        "        relationObject = relationObject + relation['object'][1] + \" | \" + relation['object'][0][0] + \" | \" + \\\n",
        "          predicate + \" = \" + trigger\n",
        "      except:\n",
        "          eventID = relation['object']['eventID']\n",
        "          relationObject = relationObject + \" \".join(create_serialized_event(relation['object'], modifiers, eventID, nested = True, roleEvent = predicate, parentEvent = trigger, nodeNumber = nodeNumber)[0])\n",
        "      relationObject = relationObject + \"]\"\n",
        "      serializedEvent.append(relationObject)\n",
        "  return serializedEvent, nodeNumber\n",
        "\n",
        "def get_indices(event):\n",
        "  indices = [int(index) for index in event['subject'][0][1:]]\n",
        "  for relation in event['relations']:   \n",
        "    if type(relation['object']) == dict: # nested event\n",
        "      indices.extend(get_indices(relation['object']))\n",
        "    else:\n",
        "      for index in relation['object'][0][1:]:\n",
        "        indices.append(int(index))\n",
        "  return indices\n",
        "\n",
        "def get_event_mentions(event, sentences): # get sentences from min to max indices\n",
        "    indices = get_indices(event)\n",
        "    minIndex = min(indices)\n",
        "    maxIndex = max(indices)\n",
        "   \n",
        "    sentences = [s['sentence'] for s in sentences \n",
        "                    if s['start_index'] <= minIndex <= s['end_index'] or\n",
        "                    s['start_index'] <= maxIndex <= s['end_index']]\n",
        "    return sentences"
      ],
      "id": "6c833377",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xktF71gasRKA"
      },
      "source": [
        "## Modifiers"
      ],
      "id": "xktF71gasRKA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUy2UexLsUI8"
      },
      "source": [
        "def set_modifier_value(modifier):\n",
        "  if modifier == \"Polarity\":\n",
        "    value = \"Negative\"\n",
        "  elif modifier == \"Speculation\":\n",
        "    value = \"True\"\n",
        "  else:\n",
        "    value = \"None\"\n",
        "  return value\n",
        "\n",
        "def prepare_modifiers(prediction):\n",
        "  modifiers = {}\n",
        "  for key, value in prediction.items():\n",
        "    if 'M' in key or 'A' in key:\n",
        "      eventID = value[0][1]\n",
        "      modifier = value[0][0]\n",
        "      modifierValue = \"\"\n",
        "      try: ## if modifier value is present\n",
        "        modifierValue = value[0][2]\n",
        "      except: ## else choose its default value\n",
        "        modifierValue = set_modifier_value(modifier)\n",
        "      # (Negation = True) = (polarity = False) \n",
        "      modifier = \"Polarity\" if modifier == \"Negation\" else modifier\n",
        "      if eventID not in modifiers.keys():\n",
        "        modifiersList = []\n",
        "        modifiersList.append((modifier, modifierValue))\n",
        "        modifiers[eventID] = modifiersList\n",
        "      else:\n",
        "        modifiers[eventID].append((modifier, modifierValue))\n",
        "  return modifiers # eventID -> list(modificator, value)"
      ],
      "id": "UUy2UexLsUI8",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scompone events"
      ],
      "metadata": {
        "id": "oYC3lY-51pDR"
      },
      "id": "oYC3lY-51pDR"
    },
    {
      "cell_type": "code",
      "source": [
        "def processSquaredBrackets(row, startIndex, endIndex, structuredEvent, itemID, trigger, nestedLevel):\n",
        "  row = row[startIndex : endIndex + 1]\n",
        "  if '|' in row: # There could be squared brackets that are not events but entitities\n",
        "    matchedText = row.rsplit('|')[0].rsplit('[')[1].lstrip().rstrip()\n",
        "    itemType = row.rsplit('|')[1].split(\"]\")[0].lstrip().rstrip()\n",
        "    if trigger:\n",
        "      modifiers = [modificator.strip() for modificator in row.rsplit('|')[2:] for modificator in modificator.split(\"]\")[0].split(\"=\")] if nestedLevel == 0 else [modificator.strip() for modificator in row.rsplit('|')[2:-1] for modificator in modificator.split(\"]\")[0].split(\"=\")]\n",
        "      item = {\"item\": (matchedText, itemType), \"modifiers\": tuple(modifiers)}\n",
        "    else:\n",
        "      role, macthedTriggerText = row.rsplit('|')[-1].rsplit(']')[0].rsplit('=')\n",
        "      item = (matchedText, itemType, role.lstrip().rstrip(), \n",
        "              macthedTriggerText.lstrip().rstrip())\n",
        "    if not itemID in structuredEvent.keys():\n",
        "      structuredEvent[itemID] = []\n",
        "    structuredEvent[itemID].append(item)  \n",
        "\n",
        "def scompone_event(row):\n",
        "  nestedLevel = 0\n",
        "  structuredEvent = {}\n",
        "  lastBracket = ''\n",
        "  itemVisited = 0 # resetted at every nesting level\n",
        "\n",
        "  for index, char in enumerate(row):\n",
        "    if char == '[':\n",
        "      nestedLevel += 1\n",
        "      startIndex = index\n",
        "      if lastBracket == '[':\n",
        "        itemVisited = 0\n",
        "      lastBracket = '['\n",
        "    elif char == ']':\n",
        "      nestedLevel -= 1\n",
        "      endIndex = index\n",
        "      if lastBracket != ']':\n",
        "        itemVisited += 1\n",
        "        if itemVisited == 1:\n",
        "          itemID = 'trigger'\n",
        "        elif itemVisited > 1:\n",
        "          itemID = 'entity' \n",
        "        itemID += '_nesting_' + str(nestedLevel)\n",
        "        processSquaredBrackets(row, startIndex, endIndex, structuredEvent, itemID, itemVisited == 1, nestedLevel)\n",
        "      lastBracket = ']'\n",
        "  \n",
        "  if nestedLevel != 0:\n",
        "    raise Exception(\"Error: wrong nesting in \" + str(row) + \" at level \" + str(nestedLevel))\n",
        "\n",
        "  return structuredEvent\n",
        "\n",
        "scompone_event(\"[regulating | Regulation | modifier1 = demo1 | modifier2 = demo2][[transformation | Cell_transformation  | Theme = regulating][cell | Cell | Theme = transformation]]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaEPbIULzXP4",
        "outputId": "ca4b5623-e84e-414b-a1b8-4681d591285b"
      },
      "id": "QaEPbIULzXP4",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'trigger_nesting_0': [{'item': ('regulating', 'Regulation'),\n",
              "   'modifiers': ('modifier1', 'demo1', 'modifier2', 'demo2')}],\n",
              " 'trigger_nesting_1': [{'item': ('transformation', 'Cell_transformation'),\n",
              "   'modifiers': ()}],\n",
              " 'entity_nesting_1': [('cell', 'Cell', 'Theme', 'transformation')]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVjMp46z7ot7"
      },
      "source": [
        "# Core EGV/EE datasets creation"
      ],
      "id": "MVjMp46z7ot7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxoJeXIl6cUj"
      },
      "source": [
        "In order to perform a smarter splitting in training/validation/test sets, a class label has been added for each row. \n",
        "Class label (EGV) consists in a jointly rappresentation of 4 elements:\n",
        "DATASET_NAME - EVENT_TYPE - NUMBER_OF_EVENT_MENTIONS"
      ],
      "id": "UxoJeXIl6cUj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e443d4",
        "outputId": "05665bcc-d353-4302-ca0a-5b8ff4b7f6f9"
      },
      "source": [
        "numberEvents = 0\n",
        "problematicEvents = 0\n",
        "singleEvents = 0\n",
        "datasetEGV = [] #(event) -> event_mentions\n",
        "datasetEE = [] #(event_mention) -> event\n",
        "\n",
        "for datasetName in tqdm(predictions.keys()):\n",
        "  for file_number, prediction in enumerate(predictions[datasetName][:]): # text by text\n",
        "    abstract = abstracts[datasetName][file_number]\n",
        "    sentences = sentence_tokenization(abstracts[datasetName][file_number])\n",
        "    senteces_without_event = set([sentence['sentence'] for sentence in sentences])\n",
        "    events = {k: v for k, v in prediction.items() if 'E' in k}\n",
        "    modifiers = prepare_modifiers(prediction)\n",
        "    for event in events.items():\n",
        "        eventID = event[0]\n",
        "        row = {}\n",
        "        numberEvents += 1\n",
        "        try:\n",
        "          myEvent = create_event(datasetName, file_number, event)\n",
        "          serializedEvent, nodeNumber = create_serialized_event(myEvent, modifiers, eventID)\n",
        "          event_mentions = get_event_mentions(myEvent, sentences)\n",
        "\n",
        "          # create row\n",
        "          row['event'] = \" \".join(serializedEvent).replace(\" [\", \"[\").replace(\"[ \", \"[\").replace(\" ]\", \"]\").replace(\"] \", \"]\")\n",
        "          row['event_mention'] = str(event_mentions)\n",
        "          row['class_for_splitting'] = datasetName + \" \" + myEvent['subject'][0][0] + \" \" + str(len(event_mentions))\n",
        "          \n",
        "          if not nodeNumber == 1:\n",
        "            datasetEGV.append(row)\n",
        "          else:\n",
        "            singleEvents == 1\n",
        "          if len(event_mentions) == 1:\n",
        "            senteces_without_event = set(senteces_without_event).difference(event_mentions)\n",
        "            row['event_mention'] = event_mentions[0]\n",
        "            row['class_for_splitting'] = datasetName + \" \" + select_sentence_class(row['event_mention']) # possibly multiple events per sentence.\n",
        "            datasetEE.append(row)\n",
        "        except:\n",
        "          problematicEvents += 1\n",
        "    for sentence in senteces_without_event: # append negative examples\n",
        "      datasetEE.append({'event': \"\", 'event_mention': sentence, 'class_for_splitting': datasetName + \" \" + select_sentence_class(sentence)})\n",
        "print(os.linesep + \"Total events: \" + str(numberEvents))\n",
        "print(\"Deleted \" + str(problematicEvents) + \" nested problematic events\")\n",
        "print(\"Deleted \" + str(singleEvents) + \" single node events in EGV\")\n",
        "print(os.linesep + \"Dataset EGV with \" + str(len(datasetEGV)) + \" examples created.\")\n",
        "print(os.linesep + \"Dataset EE with \" + str(len(datasetEE)) + \" examples created.\")"
      ],
      "id": "d6e443d4",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [04:14<00:00, 25.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total events: 100083\n",
            "Deleted 15 nested problematic events\n",
            "Deleted 0 single node events in EGV\n",
            "\n",
            "Dataset EGV with 96929 examples created.\n",
            "\n",
            "Dataset EE with 117209 examples created.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KCS6OLdaW3x"
      },
      "source": [
        "<a name=\"datasets-maniuplation\"></a>\n",
        "## Datasets manipulatation"
      ],
      "id": "_KCS6OLdaW3x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIBgiI9GZHqJ"
      },
      "source": [
        "Sometimes an event is a substring of anothers. With `clean_set` function, we mantain only the most complete one. With `select_sentence_class` function we map each sentence to its length class."
      ],
      "id": "xIBgiI9GZHqJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YIdzw5kpGVA"
      },
      "source": [
        "# Delete all duplicates\n",
        "dfEGV = pd.DataFrame(datasetEGV).drop_duplicates(subset='event')\n",
        "\n",
        "# Delete all rows that belong to a restricted class\n",
        "dfEGV = dfEGV[dfEGV.groupby('class_for_splitting').class_for_splitting.transform('count') > min_class_occurance]"
      ],
      "id": "5YIdzw5kpGVA",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to decide thresholds in sentences classes."
      ],
      "metadata": {
        "id": "Xtz_dgWI7lgj"
      },
      "id": "Xtz_dgWI7lgj"
    },
    {
      "cell_type": "code",
      "source": [
        "dfEE = pd.DataFrame(datasetEE)\n",
        "vector_lengths = []\n",
        "for sentence in dfEE['event_mention']:\n",
        "  vector_lengths.append(len(sentence))\n",
        "\n",
        "smallThreshold = pd.Series(vector_lengths).quantile(q=0.33, interpolation='linear') # prints 123\n",
        "mediumThreshold = pd.Series(vector_lengths).quantile(q=0.66, interpolation='linear') # prints 182\n",
        "largeThreshold = pd.Series(vector_lengths).quantile(q=1, interpolation='linear')"
      ],
      "metadata": {
        "id": "xC9y_dBc0ap7"
      },
      "id": "xC9y_dBc0ap7",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN_SEP = \" \"\n",
        "\n",
        "def manipulate_dataframe(row):\n",
        "  # how many events? if there's at least one event number of separator + 1, else 0.\n",
        "  number_events = row['event'].count(f' {TOKEN_SEP} ') + 1 if not len(row['event']) == 0 else 0\n",
        "  class_for_splitting_items = row['class_for_splitting'].split(\" \")\n",
        "  row['dataset'] = class_for_splitting_items[0]\n",
        "\n",
        "  if number_events > 1:\n",
        "    symbol = \"+\"\n",
        "  elif number_events == 0:\n",
        "    symbol = \"None\"\n",
        "  elif number_events == 1:\n",
        "    symbol = row['event'].split(\"|\")[1].split(\"]\")[0].strip(\" \")\n",
        "  row['class_for_splitting'] = class_for_splitting_items[0] + \" \" + symbol + \" \" + class_for_splitting_items[1]\n",
        "  return row\n",
        "\n",
        "drop_duplicates = True\n",
        "cut_unrepresentative_classes = True\n",
        "\n",
        "dfEE = pd.DataFrame(datasetEE)\n",
        "if drop_duplicates:\n",
        "  dfEE = dfEE.drop_duplicates([\"event\", \"event_mention\"]) # insert class_for_splitting to mantain same sentence from different source\n",
        "else:\n",
        "  dfEE[dfEE.duplicated(subset=[\"event_mention\"], keep=False)].sort_values(\"event_mention\")\n",
        "\n",
        "dfEE = dfEE.groupby(by=['event_mention', 'class_for_splitting']) # group by sentence\n",
        "dfEE = dfEE['event'].apply(lambda event: f' {TOKEN_SEP} '.join(clean_set(list(event)))).reset_index() # concatenate each correlated event\n",
        "dfEE = dfEE.apply(lambda row: manipulate_dataframe(row), axis=1) #axis = 1 means row by row\n",
        "\n",
        "dfEE = dfEE.sort_values([\"class_for_splitting\"]).drop_duplicates(\"event_mention\", keep=\"last\") # mantain only genia-mk when there's a conflict\n",
        "\n",
        "if cut_unrepresentative_classes:\n",
        "  dfEE = dfEE[dfEE.groupby('class_for_splitting').class_for_splitting.transform('count') > 1]\n",
        "\n",
        "dfEE.loc[dfEE['event'] == \"\", \"event\"] = \"ND\"\n",
        "dfEE = dfEE.replace(\"\\n\", \" \", regex=True)"
      ],
      "metadata": {
        "id": "ObuPsLwa6dWZ",
        "outputId": "27b55d86-a98b-4d6a-b7d6-61d26247548d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ObuPsLwa6dWZ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:723: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting EGV\n",
        "The whole dataset has been splitted in train/validation/test sets, according to the distribution of classes (they are indicated in the column `class_for_splitting`). "
      ],
      "metadata": {
        "id": "ja6rBLTHNQv4"
      },
      "id": "ja6rBLTHNQv4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIVb9rtVojgF",
        "outputId": "03237fcc-3f35-4f5e-bc10-fc5f4eef2df5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dfEGV.drop('event_mention', axis=1), dfEGV['event_mention'], \\\n",
        "                                                    test_size=test_size_ratio, random_state=random_seed, \\\n",
        "                                                    stratify=dfEGV['class_for_splitting'])\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=random_seed)\n",
        "print(\"Training set EGV size: \" + str(X_train.shape[0]))\n",
        "print(\"Validation set EGV size: \" + str(X_validation.shape[0]))\n",
        "print(\"Test set EGV size: \" + str(X_test.shape[0]))\n",
        "print(\"Total EGV size: \" + str(X_train.shape[0] + X_validation.shape[0] + X_test.shape[0]))"
      ],
      "id": "gIVb9rtVojgF",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set EGV size: 61332\n",
            "Validation set EGV size: 3407\n",
            "Test set EGV size: 3408\n",
            "Total EGV size: 68147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting EE"
      ],
      "metadata": {
        "id": "HSTi9Lh6OL7D"
      },
      "id": "HSTi9Lh6OL7D"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMbUJWHdIE0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88061162-22a5-4e8e-fd4d-2547d3687569"
      },
      "source": [
        "X_train_ee, X_test_ee, y_train_ee, y_test_ee = train_test_split(dfEE['event_mention'], dfEE.drop('event_mention', axis=1), \\\n",
        "                                                                test_size=test_size_ratio, random_state=random_seed, \\\n",
        "                                                                stratify=dfEE['class_for_splitting'])\n",
        "X_validation_ee, X_test_ee, y_validation_ee, y_test_ee = train_test_split(X_test_ee, y_test_ee, test_size=0.5, random_state=random_seed)\n",
        "print(\"Training set EE size: \" + str(X_train_ee.shape[0]))\n",
        "print(\"Validation set EE size: \" + str(X_validation_ee.shape[0]))\n",
        "print(\"Test set EE size: \" + str(X_test_ee.shape[0]))\n",
        "print(\"Total EE size: \" + str(X_train_ee.shape[0] + X_validation_ee.shape[0] + X_test_ee.shape[0]))"
      ],
      "id": "PMbUJWHdIE0n",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set EE size: 32107\n",
            "Validation set EE size: 1784\n",
            "Test set EE size: 1784\n",
            "Total EE size: 35675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ogMHGH4642r"
      },
      "source": [
        "## Export datasets"
      ],
      "id": "5ogMHGH4642r"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "o9LVmDXmj_A3",
        "outputId": "9dfed395-d2bf-4a37-fe85-24b189d9aa9b"
      },
      "source": [
        "train = pd.concat([X_train.drop(['class_for_splitting'], axis=1), y_train], axis=1)\n",
        "validation = pd.concat([X_validation.drop(['class_for_splitting'], axis=1), y_validation], axis=1)\n",
        "test = pd.concat([X_test.drop(['class_for_splitting'], axis=1), y_test], axis=1)\n",
        "\n",
        "train_ee = pd.concat([X_train_ee, y_train_ee.drop(['class_for_splitting'], axis=1)], axis=1)\n",
        "validation_ee = pd.concat([X_validation_ee, y_validation_ee.drop(['class_for_splitting'], axis=1)], axis=1)\n",
        "test_ee = pd.concat([X_test_ee, y_test_ee.drop(['class_for_splitting'], axis=1)], axis=1)\n",
        "\n",
        "train.to_csv(train_set_name + datasets_type, index=False, sep=datasets_separator)\n",
        "validation.to_csv(validation_set_name + datasets_type, index=False, sep=datasets_separator)\n",
        "test.to_csv(test_set_name + datasets_type, index=False, sep=datasets_separator)\n",
        "\n",
        "train_ee.to_csv(train_set_name + \"_ee\" + datasets_type, index=False, sep=datasets_separator)\n",
        "validation_ee.to_csv(validation_set_name + \"_ee\" + datasets_type, index=False, sep=datasets_separator)\n",
        "test_ee.to_csv(test_set_name + \"_ee\" + datasets_type, index=False, sep=datasets_separator)\n",
        "\n",
        "!zip dataset.zip *.t*\n",
        "!rm *.tsv\n",
        "files.download(dataset_file_name)"
      ],
      "id": "o9LVmDXmj_A3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: test_ee.tsv (deflated 73%)\n",
            "  adding: test.tsv (deflated 76%)\n",
            "  adding: train_ee.tsv (deflated 74%)\n",
            "  adding: train.tsv (deflated 76%)\n",
            "  adding: validation_ee.tsv (deflated 74%)\n",
            "  adding: validation.tsv (deflated 76%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a8ae1cc2-f89a-4b7b-ba91-2cae502973e9\", \"dataset.zip\", 10309476)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIwF6z957Bor"
      },
      "source": [
        "# Statistics\n",
        "Each cell contains two sub-cells. The first one is related to EGV, the last one to EE."
      ],
      "id": "KIwF6z957Bor"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Event types"
      ],
      "metadata": {
        "id": "FgQZ5RAIOdln"
      },
      "id": "FgQZ5RAIOdln"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "eventTypes = set()\n",
        "for row in dfEGV['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))\n",
        "\n",
        "eventTypes = set()\n",
        "for row in X_train['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))\n",
        "\n",
        "eventTypes = set()\n",
        "for row in X_validation['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))\n",
        "\n",
        "eventTypes = set()\n",
        "for row in X_test['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))"
      ],
      "metadata": {
        "id": "Of6Yzr93p_z9",
        "outputId": "151374f7-1970-45ad-a32f-b5b9d2fb131e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Of6Yzr93p_z9",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166\n",
            "163\n",
            "101\n",
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "eventTypes = set()\n",
        "for row in dfEE['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))\n",
        "\n",
        "eventTypes = set()\n",
        "for row in y_train_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))\n",
        "\n",
        "eventTypes = set()\n",
        "for row in y_validation_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))\n",
        "\n",
        "eventTypes = set()\n",
        "for row in y_test_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            triggerType = eventItems[key][0]['item'][1]\n",
        "            eventTypes.add(triggerType)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(eventTypes))"
      ],
      "metadata": {
        "outputId": "f5d0f299-e554-4a98-fd02-73b74729e038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ecrjrAiUQDt"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n",
            "159\n",
            "86\n",
            "84\n"
          ]
        }
      ],
      "id": "6ecrjrAiUQDt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity types"
      ],
      "metadata": {
        "id": "ZXQDS84AwjSL"
      },
      "id": "ZXQDS84AwjSL"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "entityTypes = set()\n",
        "for row in dfEGV['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))\n",
        "\n",
        "entityTypes = set()\n",
        "for row in X_train['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))\n",
        "\n",
        "entityTypes = set()\n",
        "for row in X_validation['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))\n",
        "\n",
        "entityTypes = set()\n",
        "for row in X_test['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b3b73a-b149-41a1-a476-bd10e8e1bb5a",
        "id": "--VFV7DoUdye"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n",
            "146\n",
            "93\n",
            "84\n"
          ]
        }
      ],
      "id": "--VFV7DoUdye"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "entityTypes = set()\n",
        "for row in dfEE['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))\n",
        "\n",
        "entityTypes = set()\n",
        "for row in y_train_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))\n",
        "\n",
        "entityTypes = set()\n",
        "for row in y_validation_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))\n",
        "\n",
        "entityTypes = set()\n",
        "for row in y_test_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            entityTypes.add(entities[1])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(entityTypes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqmmcb8_wvr_",
        "outputId": "4f228acf-6b87-420a-d5f5-1842b43f5a24"
      },
      "id": "Fqmmcb8_wvr_",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132\n",
            "129\n",
            "54\n",
            "58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Role types"
      ],
      "metadata": {
        "id": "skqYssq95Bjj"
      },
      "id": "skqYssq95Bjj"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "roleTypes = set()\n",
        "for row in dfEGV['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))\n",
        "\n",
        "roleTypes = set()\n",
        "for row in X_train['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))\n",
        "\n",
        "roleTypes = set()\n",
        "for row in X_validation['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))\n",
        "\n",
        "roleTypes = set()\n",
        "for row in X_test['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4cd614a-3a21-41dd-ac80-8b558932166e",
        "id": "jXytHV9jVEv4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "19\n",
            "13\n",
            "14\n"
          ]
        }
      ],
      "id": "jXytHV9jVEv4"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "roleTypes = set()\n",
        "for row in dfEE['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))\n",
        "\n",
        "roleTypes = set()\n",
        "for row in y_train_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))\n",
        "\n",
        "roleTypes = set()\n",
        "for row in y_validation_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))\n",
        "\n",
        "roleTypes = set()\n",
        "for row in y_test_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"entity\" in key:\n",
        "            entities = eventItems[key][0]\n",
        "            roleTypes.add(entities[2])\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(roleTypes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUb62SAr5GUN",
        "outputId": "de98ed86-47e3-4887-ce8b-4387796c39db"
      },
      "id": "nUb62SAr5GUN",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "19\n",
            "13\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifier types"
      ],
      "metadata": {
        "id": "mIzcuOjg_nXx"
      },
      "id": "mIzcuOjg_nXx"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "modifiersTypes = set()\n",
        "for row in dfEGV['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiers = eventItems[key][0]['modifiers']\n",
        "            for modifier in modifiers[0::2]:\n",
        "              modifiersTypes.add(modifier)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(modifiersTypes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ja6p6g0RsZT",
        "outputId": "26cfe511-768c-4440-e3cf-ab256a92b8f7"
      },
      "id": "7Ja6p6g0RsZT",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "modifiersTypes = set()\n",
        "for row in dfEE['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiers = eventItems[key][0]['modifiers']\n",
        "            for modifier in modifiers[0::2]:\n",
        "              modifiersTypes.add(modifier)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(modifiersTypes))\n",
        "\n",
        "modifiersTypes = set()\n",
        "for row in y_train_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiers = eventItems[key][0]['modifiers']\n",
        "            for modifier in modifiers[0::2]:\n",
        "              modifiersTypes.add(modifier)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(modifiersTypes))\n",
        "\n",
        "modifiersTypes = set()\n",
        "for row in y_validation_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiers = eventItems[key][0]['modifiers']\n",
        "            for modifier in modifiers[0::2]:\n",
        "              modifiersTypes.add(modifier)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(modifiersTypes))\n",
        "\n",
        "modifiersTypes = set()\n",
        "for row in y_test_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiers = eventItems[key][0]['modifiers']\n",
        "            for modifier in modifiers[0::2]:\n",
        "              modifiersTypes.add(modifier)\n",
        "      except:\n",
        "        error += 1\n",
        "print(len(modifiersTypes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kqU9EWLJ6i_",
        "outputId": "fe228943-f4ad-47e0-dddc-cf47fc7d2476"
      },
      "id": "5kqU9EWLJ6i_",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "6\n",
            "6\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes per event"
      ],
      "metadata": {
        "id": "i7FuOfNFV8MS"
      },
      "id": "i7FuOfNFV8MS"
    },
    {
      "cell_type": "code",
      "source": [
        "numberNodes = []\n",
        "\n",
        "for index, row in dfEGV.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())\n",
        "\n",
        "numberNodes = []\n",
        "\n",
        "for index, row in X_train.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())\n",
        "\n",
        "numberNodes = []\n",
        "\n",
        "for index, row in X_validation.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())\n",
        "\n",
        "numberNodes = []\n",
        "\n",
        "for index, row in X_test.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())"
      ],
      "metadata": {
        "outputId": "1cf382e3-250a-4c91-9aec-b0a7845696a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzK6EJ1yVctF"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    68147.000000\n",
            "mean         4.291942\n",
            "std          2.689906\n",
            "min          2.000000\n",
            "25%          2.000000\n",
            "50%          3.000000\n",
            "75%          5.000000\n",
            "max         35.000000\n",
            "dtype: float64\n",
            "count    61332.000000\n",
            "mean         4.291707\n",
            "std          2.691245\n",
            "min          2.000000\n",
            "25%          2.000000\n",
            "50%          3.000000\n",
            "75%          5.000000\n",
            "max         35.000000\n",
            "dtype: float64\n",
            "count    3407.000000\n",
            "mean        4.260053\n",
            "std         2.651050\n",
            "min         2.000000\n",
            "25%         2.000000\n",
            "50%         3.000000\n",
            "75%         5.000000\n",
            "max        35.000000\n",
            "dtype: float64\n",
            "count    3408.000000\n",
            "mean        4.328052\n",
            "std         2.704682\n",
            "min         2.000000\n",
            "25%         2.000000\n",
            "50%         3.000000\n",
            "75%         5.000000\n",
            "max        33.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "id": "lzK6EJ1yVctF"
    },
    {
      "cell_type": "code",
      "source": [
        "numberNodes = []\n",
        "\n",
        "for index, row in dfEE.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())\n",
        "\n",
        "numberNodes = []\n",
        "\n",
        "for index, row in y_train_ee.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())\n",
        "\n",
        "numberNodes = []\n",
        "\n",
        "for index, row in y_validation_ee.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())\n",
        "\n",
        "numberNodes = []\n",
        "\n",
        "for index, row in y_test_ee.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      numberNodes.append(event.count(\"]\"))\n",
        "\n",
        "print(pd.Series(numberNodes).describe())"
      ],
      "metadata": {
        "id": "yfHO-aq1V-cX",
        "outputId": "154ab4bf-08db-47f6-9e0f-7bc0aa6215a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yfHO-aq1V-cX",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    66255.000000\n",
            "mean         2.351596\n",
            "std          2.254288\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          2.000000\n",
            "75%          3.000000\n",
            "max         20.000000\n",
            "dtype: float64\n",
            "count    59636.000000\n",
            "mean         2.354316\n",
            "std          2.255126\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          2.000000\n",
            "75%          3.000000\n",
            "max         20.000000\n",
            "dtype: float64\n",
            "count    3272.000000\n",
            "mean        2.290342\n",
            "std         2.186377\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         2.000000\n",
            "75%         3.000000\n",
            "max        18.000000\n",
            "dtype: float64\n",
            "count    3347.000000\n",
            "mean        2.363012\n",
            "std         2.303999\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         2.000000\n",
            "75%         3.000000\n",
            "max        15.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifiers per event"
      ],
      "metadata": {
        "id": "-_7o-HPcN46_"
      },
      "id": "-_7o-HPcN46_"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in dfEGV['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in X_train['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in X_validation['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in X_test['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81652d4-ac79-4820-c35a-f17c7223f3e7",
        "id": "rdHenZwEU0IY"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    103797.000000\n",
            "mean          2.424164\n",
            "std           2.467239\n",
            "min           0.000000\n",
            "25%           0.000000\n",
            "50%           1.000000\n",
            "75%           5.000000\n",
            "max           5.000000\n",
            "dtype: float64\n",
            "count    93393.000000\n",
            "mean         2.426595\n",
            "std          2.467427\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          1.000000\n",
            "75%          5.000000\n",
            "max          5.000000\n",
            "dtype: float64\n",
            "count    5170.000000\n",
            "mean        2.408317\n",
            "std         2.466610\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         1.000000\n",
            "75%         5.000000\n",
            "max         5.000000\n",
            "dtype: float64\n",
            "count    5234.000000\n",
            "mean        2.396446\n",
            "std         2.464748\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         1.000000\n",
            "75%         5.000000\n",
            "max         5.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "id": "rdHenZwEU0IY"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in dfEE['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in y_train_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in y_validation_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())\n",
        "\n",
        "modifiersNumber = []\n",
        "for row in y_test_ee['event'][:]:\n",
        "  events = row.split(f' {TOKEN_SEP} ')\n",
        "  for event in events:\n",
        "    if len(event) > 0:\n",
        "      try:\n",
        "        eventItems = scompone_event(event)\n",
        "        for key in eventItems.keys():\n",
        "          if \"trigger\" in key:\n",
        "            modifiersNumber.append(len(eventItems[key][0]['modifiers'][0::2]))\n",
        "      except:\n",
        "        error += 1\n",
        "print(pd.Series(modifiersNumber).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itBRMnfaN8BB",
        "outputId": "1b4904c5-0ab0-4aa8-dbe0-089598c04b57"
      },
      "id": "itBRMnfaN8BB",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    64618.000000\n",
            "mean         0.516156\n",
            "std          1.439591\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max          5.000000\n",
            "dtype: float64\n",
            "count    58241.000000\n",
            "mean         0.519222\n",
            "std          1.443336\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max          5.000000\n",
            "dtype: float64\n",
            "count    3128.000000\n",
            "mean        0.517583\n",
            "std         1.437876\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.000000\n",
            "max         5.000000\n",
            "dtype: float64\n",
            "count    3249.000000\n",
            "mean        0.459834\n",
            "std         1.371666\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.000000\n",
            "max         5.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentences per event mention"
      ],
      "metadata": {
        "id": "n0trCzxIb0Bf"
      },
      "id": "n0trCzxIb0Bf"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "sentencesPerEventMention = []\n",
        "for row in dfEGV['event_mention'][:]:\n",
        "  try:\n",
        "    number_event_mentions = row.count(\"'\") // 2 if \"['\" in row else 1\n",
        "    sentencesPerEventMention.append(number_event_mentions)\n",
        "  except:\n",
        "    error += 1\n",
        "print(pd.Series(sentencesPerEventMention).describe())\n",
        "\n",
        "sentencesPerEventMention = []\n",
        "for row in y_train[:]:\n",
        "  try:\n",
        "    number_event_mentions = row.count(\"'\") // 2 if \"['\" in row else 1\n",
        "    sentencesPerEventMention.append(number_event_mentions)\n",
        "  except:\n",
        "    error += 1\n",
        "print(pd.Series(sentencesPerEventMention).describe())\n",
        "\n",
        "sentencesPerEventMention = []\n",
        "for row in y_validation[:]:\n",
        "  try:\n",
        "    number_event_mentions = row.count(\"'\") // 2 if \"['\" in row else 1\n",
        "    sentencesPerEventMention.append(number_event_mentions)\n",
        "  except:\n",
        "    error += 1\n",
        "print(pd.Series(sentencesPerEventMention).describe())\n",
        "\n",
        "sentencesPerEventMention = []\n",
        "for row in y_test[:]:\n",
        "  try:\n",
        "    number_event_mentions = row.count(\"'\") // 2 if \"['\" in row else 1\n",
        "    sentencesPerEventMention.append(number_event_mentions)\n",
        "  except:\n",
        "    error += 1\n",
        "print(pd.Series(sentencesPerEventMention).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d56b70-c508-447e-a03d-f4fd27c71daa",
        "id": "tHK9PWJ_b0Bo"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    68147.000000\n",
            "mean         1.137878\n",
            "std          0.359690\n",
            "min          1.000000\n",
            "25%          1.000000\n",
            "50%          1.000000\n",
            "75%          1.000000\n",
            "max          3.000000\n",
            "dtype: float64\n",
            "count    61332.000000\n",
            "mean         1.137840\n",
            "std          0.359461\n",
            "min          1.000000\n",
            "25%          1.000000\n",
            "50%          1.000000\n",
            "75%          1.000000\n",
            "max          3.000000\n",
            "dtype: float64\n",
            "count    3407.000000\n",
            "mean        1.132375\n",
            "std         0.353366\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         1.000000\n",
            "75%         1.000000\n",
            "max         3.000000\n",
            "dtype: float64\n",
            "count    3408.000000\n",
            "mean        1.144073\n",
            "std         0.369937\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         1.000000\n",
            "75%         1.000000\n",
            "max         3.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "id": "tHK9PWJ_b0Bo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokens per event mention"
      ],
      "metadata": {
        "id": "UHPA2jPv79pI"
      },
      "id": "UHPA2jPv79pI"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in dfEGV['event_mention'][:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in y_train[:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in y_validation[:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in y_test[:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())"
      ],
      "metadata": {
        "outputId": "aa7bfe1f-2874-4a3e-9885-d83e07d54755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J5fOPjsPndp"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    68147.000000\n",
            "mean        63.267613\n",
            "std         34.120959\n",
            "min          6.000000\n",
            "25%         40.000000\n",
            "50%         55.000000\n",
            "75%         77.000000\n",
            "max        407.000000\n",
            "dtype: float64\n",
            "count    61332.000000\n",
            "mean        63.307164\n",
            "std         34.215564\n",
            "min          6.000000\n",
            "25%         40.000000\n",
            "50%         55.000000\n",
            "75%         77.000000\n",
            "max        407.000000\n",
            "dtype: float64\n",
            "count    3407.000000\n",
            "mean       62.607866\n",
            "std        33.416095\n",
            "min        10.000000\n",
            "25%        40.000000\n",
            "50%        54.000000\n",
            "75%        76.000000\n",
            "max       313.000000\n",
            "dtype: float64\n",
            "count    3408.000000\n",
            "mean       63.215376\n",
            "std        33.100881\n",
            "min        12.000000\n",
            "25%        40.000000\n",
            "50%        55.000000\n",
            "75%        78.000000\n",
            "max       407.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "id": "1J5fOPjsPndp"
    },
    {
      "cell_type": "code",
      "source": [
        "error = 0\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in dfEE['event_mention'][:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in X_train_ee[:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in X_validation_ee[:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())\n",
        "\n",
        "sentencesLengths = []\n",
        "for row in X_test_ee[:]:\n",
        "    try:\n",
        "      sentencesLengths.append(len(tokenizerT5.encode(row)))\n",
        "    except:\n",
        "      error += 1\n",
        "print(pd.Series(sentencesLengths).describe())"
      ],
      "metadata": {
        "id": "W9LiUQy35zek",
        "outputId": "188ea6ef-f25e-41f2-bf0b-984501d3a241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "W9LiUQy35zek",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    35675.000000\n",
            "mean        44.342144\n",
            "std         22.584563\n",
            "min          1.000000\n",
            "25%         29.000000\n",
            "50%         40.000000\n",
            "75%         55.000000\n",
            "max        381.000000\n",
            "dtype: float64\n",
            "count    32107.000000\n",
            "mean        44.320273\n",
            "std         22.536463\n",
            "min          1.000000\n",
            "25%         30.000000\n",
            "50%         40.000000\n",
            "75%         55.000000\n",
            "max        381.000000\n",
            "dtype: float64\n",
            "count    1784.000000\n",
            "mean       44.712444\n",
            "std        22.666069\n",
            "min         2.000000\n",
            "25%        30.000000\n",
            "50%        41.000000\n",
            "75%        54.000000\n",
            "max       217.000000\n",
            "dtype: float64\n",
            "count    1784.000000\n",
            "mean       44.365471\n",
            "std        23.364095\n",
            "min         2.000000\n",
            "25%        29.000000\n",
            "50%        40.000000\n",
            "75%        54.000000\n",
            "max       183.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Events per event mentions"
      ],
      "metadata": {
        "id": "SZ5rK_ZpBo2X"
      },
      "id": "SZ5rK_ZpBo2X"
    },
    {
      "cell_type": "code",
      "source": [
        "eventsPerSentence = []\n",
        "for row in dfEE['event']:\n",
        "  number_events = row.count(f' {TOKEN_SEP} ') + 1 if not len(row) == 0 else 0\n",
        "  eventsPerSentence.append(number_events)\n",
        "\n",
        "print(pd.Series(eventsPerSentence).describe())\n",
        "\n",
        "\n",
        "eventsPerSentence = []\n",
        "for row in y_train_ee['event']:\n",
        "  number_events = row.count(f' {TOKEN_SEP} ') + 1 if not len(row) == 0 else 0\n",
        "  eventsPerSentence.append(number_events)\n",
        "\n",
        "print(pd.Series(eventsPerSentence).describe())\n",
        "\n",
        "eventsPerSentence = []\n",
        "for row in y_validation_ee['event']:\n",
        "  number_events = row.count(f' {TOKEN_SEP} ') + 1 if not len(row) == 0 else 0\n",
        "  eventsPerSentence.append(number_events)\n",
        "\n",
        "print(pd.Series(eventsPerSentence).describe())\n",
        "\n",
        "eventsPerSentence = []\n",
        "for row in y_test_ee['event']:\n",
        "  number_events = row.count(f' {TOKEN_SEP} ') + 1 if not len(row) == 0 else 0\n",
        "  eventsPerSentence.append(number_events)\n",
        "\n",
        "print(pd.Series(eventsPerSentence).describe())"
      ],
      "metadata": {
        "id": "RJK0JZv1BsFd",
        "outputId": "a81ea1c8-fe4a-4b14-aa82-ff918bc51674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RJK0JZv1BsFd",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    35675.000000\n",
            "mean         1.857183\n",
            "std          1.931766\n",
            "min          1.000000\n",
            "25%          1.000000\n",
            "50%          1.000000\n",
            "75%          2.000000\n",
            "max         60.000000\n",
            "dtype: float64\n",
            "count    32107.000000\n",
            "mean         1.857414\n",
            "std          1.936216\n",
            "min          1.000000\n",
            "25%          1.000000\n",
            "50%          1.000000\n",
            "75%          2.000000\n",
            "max         60.000000\n",
            "dtype: float64\n",
            "count    1784.000000\n",
            "mean        1.834081\n",
            "std         1.810868\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         1.000000\n",
            "75%         2.000000\n",
            "max        22.000000\n",
            "dtype: float64\n",
            "count    1784.000000\n",
            "mean        1.876121\n",
            "std         1.969143\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         1.000000\n",
            "75%         2.000000\n",
            "max        21.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots\n",
        "Code to create `.csv` files in order to draw paper plots (figure 3)."
      ],
      "metadata": {
        "id": "ZpI5T3et8uUt"
      },
      "id": "ZpI5T3et8uUt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nodes per event graph"
      ],
      "metadata": {
        "id": "Va0LL6MpGRus"
      },
      "id": "Va0LL6MpGRus"
    },
    {
      "cell_type": "code",
      "source": [
        "plotEGV = {}\n",
        "\n",
        "for index, row in dfEGV.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      number_nodes = event.count(\"]\")\n",
        "      plotEGV[number_nodes] = 1 if number_nodes not in plotEGV else plotEGV[number_nodes] + 1\n",
        "\n",
        "plotEE = {}\n",
        "\n",
        "for index, row in dfEE.iterrows():\n",
        "  for event in row['event'].split(f' {TOKEN_SEP} '):\n",
        "    if len(event) > 0:\n",
        "      number_nodes = event.count(\"]\")\n",
        "      plotEE[number_nodes] = 1 if number_nodes not in plotEE else plotEE[number_nodes] + 1\n",
        "\n",
        "write_dict_to_csv('egv_nodes_per_graph.csv', plotEGV)\n",
        "files.download('egv_nodes_per_graph.csv')\n",
        "\n",
        "write_dict_to_csv('ee_nodes_per_graph.csv', plotEE)\n",
        "files.download('ee_nodes_per_graph.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vs1ZE0FXGULd",
        "outputId": "b2f13286-c5b1-43e3-c688-965b127f2885"
      },
      "id": "vs1ZE0FXGULd",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43f79d97-8a11-45aa-b295-2c646c77eba0\", \"egv_nodes_per_graph.csv\", 219)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c852cbc-2920-4c30-a2f1-cbf15aa22670\", \"ee_nodes_per_graph.csv\", 156)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokens per event graph"
      ],
      "metadata": {
        "id": "6GoBAiMMCJox"
      },
      "id": "6GoBAiMMCJox"
    },
    {
      "cell_type": "code",
      "source": [
        "plotEGV = {}\n",
        "for event in dfEGV['event']:\n",
        "  length = len(tokenizerT5.encode(event))\n",
        "  plotEGV[length] = 1 if length not in plotEGV else plotEGV[length] + 1\n",
        "\n",
        "plotEE = {}\n",
        "for row in dfEE['event']:\n",
        "  for event in row.split(f' {TOKEN_SEP} '):\n",
        "    length = len(tokenizerT5.encode(event)) if not len(event) == 0 else 0\n",
        "    plotEE[length] = 1 if length not in plotEE else plotEE[length] + 1\n",
        "\n",
        "write_dict_to_csv('egv_tokens_per_graph.csv', plotEGV)\n",
        "files.download('egv_tokens_per_graph.csv')\n",
        "\n",
        "write_dict_to_csv('ee_tokens_per_graph.csv', plotEE)\n",
        "files.download('ee_tokens_per_graph.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ficHGwQwCMPP",
        "outputId": "e45906f9-d7bd-4623-dcf4-151695ef1bdc"
      },
      "id": "ficHGwQwCMPP",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d714b0d-61ab-4308-8466-dab9489b4b90\", \"egv_tokens_per_graph.csv\", 3469)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_705a4828-9856-4e3c-82f6-a6a44ed1fb46\", \"ee_tokens_per_graph.csv\", 2182)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokens per event mention"
      ],
      "metadata": {
        "id": "0WNFXnlT-Myr"
      },
      "id": "0WNFXnlT-Myr"
    },
    {
      "cell_type": "code",
      "source": [
        "plotEGV = {}\n",
        "for sentence in dfEGV['event_mention']:\n",
        "  length = len(tokenizerT5.encode(sentence))\n",
        "  plotEGV[length] = 1 if length not in plotEGV else plotEGV[length] + 1\n",
        "\n",
        "plotEE = {}\n",
        "for sentence in dfEE['event_mention']:\n",
        "  length = len(tokenizerT5.encode(sentence))\n",
        "  plotEE[length] = 1 if length not in plotEE else plotEE[length] + 1\n",
        "\n",
        "write_dict_to_csv(\"egv_tokens_per_event_mention.csv\", plotEGV)\n",
        "files.download(\"egv_tokens_per_event_mention.csv\")\n",
        "\n",
        "write_dict_to_csv('ee_tokens_per_event_mention.csv', plotEE)\n",
        "files.download('ee_tokens_per_event_mention.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VGHfOIFf9A-j",
        "outputId": "6195876f-b23d-42a7-f846-5f612b3aa113"
      },
      "id": "VGHfOIFf9A-j",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_77ee9867-efb6-4008-b140-f506585aea73\", \"egv_tokens_per_event_mention.csv\", 1886)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af4607d5-bf34-4e24-b936-6951305c40f1\", \"ee_tokens_per_event_mention.csv\", 1527)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}